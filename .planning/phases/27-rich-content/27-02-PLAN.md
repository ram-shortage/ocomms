---
phase: 27-rich-content
plan: 02
type: execute
wave: 2
depends_on: [27-01]
files_modified:
  - src/lib/url-extractor.ts
  - src/lib/ssrf-protection.ts
  - src/server/queue/link-preview.queue.ts
  - src/workers/link-preview.worker.ts
  - src/workers/index.ts
  - src/lib/socket-events.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "URLs are extracted from message content up to 5 URLs (LINK-02)"
    - "Private/internal IPs are blocked at DNS resolution time (LINK-07)"
    - "Preview fetching is async via BullMQ, not blocking message delivery"
    - "Preview updates are broadcast via Socket.IO when ready"
  artifacts:
    - path: "src/lib/url-extractor.ts"
      provides: "extractUrls function"
      exports: ["extractUrls"]
    - path: "src/lib/ssrf-protection.ts"
      provides: "SSRF validation utilities"
      exports: ["isUrlSafe", "FILE_EXTENSIONS_TO_SKIP"]
    - path: "src/server/queue/link-preview.queue.ts"
      provides: "BullMQ queue for link preview jobs"
      exports: ["linkPreviewQueue", "LinkPreviewJobData"]
    - path: "src/workers/link-preview.worker.ts"
      provides: "Worker that fetches and caches previews"
      exports: ["createLinkPreviewWorker"]
  key_links:
    - from: "src/workers/link-preview.worker.ts"
      to: "src/db/schema/link-preview.ts"
      via: "database insert/upsert"
      pattern: "linkPreviews.*insert|upsert"
    - from: "src/workers/link-preview.worker.ts"
      to: "Socket.IO emitter"
      via: "getEmitter broadcast"
      pattern: "emitter.*emit.*linkPreview"
---

<objective>
Build link preview infrastructure with URL extraction, SSRF protection, and async BullMQ worker.

Purpose: Enable automatic link preview generation without blocking message delivery or exposing SSRF vulnerabilities (LINK-01, LINK-04, LINK-07).
Output: Complete backend pipeline from URL detection to cached preview with Socket.IO broadcast.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/27-rich-content/27-CONTEXT.md
@.planning/phases/27-rich-content/27-RESEARCH.md
@.planning/phases/27-rich-content/27-01-SUMMARY.md

Reference existing patterns:
@src/workers/scheduled-message.worker.ts
@src/server/queue/scheduled-message.queue.ts
@src/server/queue/connection.ts
@src/server/queue/emitter.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies and create URL extractor</name>
  <files>src/lib/url-extractor.ts, src/lib/ssrf-protection.ts, package.json</files>
  <action>
**Install dependencies:**
```bash
npm install unfurl.js request-filtering-agent
```

**Create src/lib/url-extractor.ts:**
```typescript
// URL regex pattern matching http:// and https:// URLs
const URL_REGEX = /https?:\/\/[^\s<>"{}|\\^`\[\]]+/gi;

export function extractUrls(content: string): string[] {
  const matches = content.match(URL_REGEX);
  if (!matches) return [];

  // Dedupe and limit to 5 (LINK-02)
  return [...new Set(matches)].slice(0, 5);
}
```

**Create src/lib/ssrf-protection.ts:**
```typescript
// File extensions to skip (CONTEXT decision: skip .pdf, .zip, etc.)
export const FILE_EXTENSIONS_TO_SKIP = [
  '.pdf', '.zip', '.exe', '.dmg', '.tar', '.gz', '.7z',
  '.rar', '.iso', '.bin', '.doc', '.docx', '.xls', '.xlsx'
];

export function isUrlSafe(url: string): boolean {
  try {
    const parsed = new URL(url);

    // Only allow http/https
    if (!['http:', 'https:'].includes(parsed.protocol)) {
      return false;
    }

    // Skip direct file links
    const pathname = parsed.pathname.toLowerCase();
    if (FILE_EXTENSIONS_TO_SKIP.some(ext => pathname.endsWith(ext))) {
      return false;
    }

    return true;
  } catch {
    return false;
  }
}
```

Note: request-filtering-agent provides DNS-level SSRF protection in the worker (validates IP after DNS resolution, not just URL string).
  </action>
  <verify>npm ls unfurl.js request-filtering-agent && npx tsc --noEmit src/lib/url-extractor.ts src/lib/ssrf-protection.ts</verify>
  <done>Dependencies installed, URL extraction and initial URL validation utilities created</done>
</task>

<task type="auto">
  <name>Task 2: Create link preview queue and worker</name>
  <files>src/server/queue/link-preview.queue.ts, src/workers/link-preview.worker.ts, src/workers/index.ts</files>
  <action>
**Create src/server/queue/link-preview.queue.ts:**
Follow scheduled-message.queue.ts pattern:
```typescript
import { Queue } from "bullmq";
import { getQueueConnection } from "./connection";

export interface LinkPreviewJobData {
  messageId: string;
  url: string;
  position: number; // Order in message (0-indexed)
}

export const linkPreviewQueue = new Queue<LinkPreviewJobData>(
  "link-previews",
  {
    connection: getQueueConnection(),
    defaultJobOptions: {
      attempts: 3,
      backoff: { type: "exponential", delay: 2000 },
      removeOnComplete: { count: 500 },
      removeOnFail: { count: 100 },
    },
  }
);
```

**Create src/workers/link-preview.worker.ts:**
```typescript
import { Worker } from "bullmq";
import { unfurl } from "unfurl.js";
import FilteringAgent from "request-filtering-agent";
import { db } from "@/db";
import { linkPreviews, messageLinkPreviews, messages } from "@/db/schema";
import { eq, and } from "drizzle-orm";
import { getQueueConnection } from "@/server/queue/connection";
import { getEmitter } from "@/server/queue/emitter";
import { isUrlSafe } from "@/lib/ssrf-protection";
import type { LinkPreviewJobData } from "@/server/queue/link-preview.queue";

const CACHE_TTL_HOURS = 24;

async function fetchAndCachePreview(
  messageId: string,
  url: string,
  position: number
): Promise<void> {
  // 1. Check URL safety (protocol, file extension)
  if (!isUrlSafe(url)) {
    console.log(`[LinkPreview] Skipping unsafe URL: ${url}`);
    return;
  }

  // 2. Check if message still exists
  const message = await db.query.messages.findFirst({
    where: eq(messages.id, messageId),
    columns: { id: true, channelId: true, conversationId: true },
  });
  if (!message) {
    console.log(`[LinkPreview] Message ${messageId} not found, skipping`);
    return;
  }

  // 3. Check cache first
  const cached = await db.query.linkPreviews.findFirst({
    where: eq(linkPreviews.url, url),
  });

  if (cached && new Date(cached.expiresAt) > new Date()) {
    // Use cached preview, just link to message
    await linkToMessage(cached.id, messageId, position, message);
    return;
  }

  // 4. Fetch metadata with SSRF protection (request-filtering-agent)
  try {
    const agent = new FilteringAgent.HttpsAgent();
    const metadata = await unfurl(url, {
      timeout: 5000,
      follow: 3,
      // Pass filtering agent for SSRF protection (blocks private IPs after DNS resolution)
      fetch: (fetchUrl, options) =>
        fetch(fetchUrl, { ...options, dispatcher: agent as never }),
    });

    const previewData = {
      url,
      title: metadata.open_graph?.title || metadata.title || null,
      description: metadata.open_graph?.description || metadata.description || null,
      imageUrl: metadata.open_graph?.images?.[0]?.url || null,
      siteName: metadata.open_graph?.site_name || null,
      fetchedAt: new Date(),
      expiresAt: new Date(Date.now() + CACHE_TTL_HOURS * 60 * 60 * 1000),
    };

    // 5. Upsert preview (update if exists, insert if not)
    let previewId: string;
    if (cached) {
      await db.update(linkPreviews)
        .set(previewData)
        .where(eq(linkPreviews.id, cached.id));
      previewId = cached.id;
    } else {
      const [inserted] = await db.insert(linkPreviews)
        .values(previewData)
        .returning({ id: linkPreviews.id });
      previewId = inserted.id;
    }

    // 6. Link to message and broadcast
    await linkToMessage(previewId, messageId, position, message);
  } catch (error) {
    // CONTEXT decision: Failed/timed out fetches silently fall back to plain hyperlink
    console.log(`[LinkPreview] Failed to fetch ${url}:`, error);
  }
}

async function linkToMessage(
  previewId: string,
  messageId: string,
  position: number,
  message: { channelId: string | null; conversationId: string | null }
): Promise<void> {
  // Insert junction record (ignore if already exists)
  await db.insert(messageLinkPreviews)
    .values({ messageId, linkPreviewId: previewId, position })
    .onConflictDoNothing();

  // Fetch full preview for broadcast
  const preview = await db.query.linkPreviews.findFirst({
    where: eq(linkPreviews.id, previewId),
  });

  if (preview) {
    // Broadcast to room
    const emitter = getEmitter();
    const room = message.channelId
      ? `channel:${message.channelId}`
      : `dm:${message.conversationId}`;

    emitter.to(room).emit("linkPreview:ready", {
      messageId,
      previews: [{
        id: preview.id,
        url: preview.url,
        title: preview.title,
        description: preview.description,
        imageUrl: preview.imageUrl,
        siteName: preview.siteName,
      }],
    });

    console.log(`[LinkPreview] Preview ready for ${preview.url} -> ${messageId}`);
  }
}

export function createLinkPreviewWorker(): Worker<LinkPreviewJobData> {
  return new Worker<LinkPreviewJobData>(
    "link-previews",
    async (job) => {
      console.log(`[LinkPreview] Processing job ${job.id} for ${job.data.url}`);
      await fetchAndCachePreview(job.data.messageId, job.data.url, job.data.position);
    },
    {
      connection: getQueueConnection(),
      concurrency: 10, // Higher concurrency for fetch-heavy work
    }
  );
}
```

**Update src/workers/index.ts:**
Add import and instantiate the link preview worker alongside existing workers:
```typescript
import { createLinkPreviewWorker } from "./link-preview.worker";

// In the worker setup section:
const linkPreviewWorker = createLinkPreviewWorker();

// In graceful shutdown:
await linkPreviewWorker.close();
```
  </action>
  <verify>npx tsc --noEmit src/server/queue/link-preview.queue.ts src/workers/link-preview.worker.ts src/workers/index.ts</verify>
  <done>Link preview queue defined, worker fetches metadata with SSRF protection and broadcasts via Socket.IO</done>
</task>

<task type="auto">
  <name>Task 3: Add Socket.IO event types</name>
  <files>src/lib/socket-events.ts</files>
  <action>
Add link preview events to ServerToClientEvents interface:

```typescript
// Add to ServerToClientEvents:
"linkPreview:ready": (data: {
  messageId: string;
  previews: Array<{
    id: string;
    url: string;
    title: string | null;
    description: string | null;
    imageUrl: string | null;
    siteName: string | null;
  }>;
}) => void;

"linkPreview:hidden": (data: {
  messageId: string;
  previewId: string;
}) => void;
```

These events enable:
- linkPreview:ready: Worker broadcasts when preview is fetched and cached
- linkPreview:hidden: User hides a preview on their own message (LINK-06)
  </action>
  <verify>npx tsc --noEmit src/lib/socket-events.ts</verify>
  <done>Socket.IO event types defined for link preview updates</done>
</task>

</tasks>

<verification>
- [ ] npm ls unfurl.js request-filtering-agent shows installed
- [ ] npx tsc --noEmit passes for all new files
- [ ] extractUrls("Check https://example.com and https://test.com/path") returns 2 URLs
- [ ] isUrlSafe("https://example.com/file.pdf") returns false
- [ ] Worker file imports compile without circular dependency issues
</verification>

<success_criteria>
Link preview backend pipeline complete:
- URLs extracted from message content (max 5, LINK-02)
- SSRF protection via request-filtering-agent (LINK-07)
- Async fetching via BullMQ (non-blocking)
- 24-hour cache TTL (LINK-04)
- Socket.IO broadcast when preview ready
</success_criteria>

<output>
After completion, create `.planning/phases/27-rich-content/27-02-SUMMARY.md`
</output>
