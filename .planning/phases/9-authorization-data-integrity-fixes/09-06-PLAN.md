---
phase: 09-authorization-data-integrity-fixes
plan: 06
type: execute
wave: 2
depends_on: []
files_modified:
  - src/server/socket/handlers/message.ts
  - src/server/socket/handlers/thread.ts
  - src/db/schema/message.ts
  - prisma/migrations (new migration)
autonomous: true

must_haves:
  truths:
    - "Message sequences are unique per channel/conversation (no duplicates from race conditions)"
    - "INSERT uses atomic sequence generation, not SELECT then INSERT pattern"
    - "Database has unique constraints preventing duplicate sequences"
  artifacts:
    - path: "src/server/socket/handlers/message.ts"
      provides: "Atomic sequence generation for messages"
      contains: "INSERT.*SELECT.*MAX"
    - path: "src/server/socket/handlers/thread.ts"
      provides: "Atomic sequence generation for thread replies"
      contains: "INSERT.*SELECT.*MAX"
    - path: "src/db/schema/message.ts"
      provides: "Unique constraint on (channelId, sequence) and (conversationId, sequence)"
      contains: "uniqueIndex"
  key_links:
    - from: "src/server/socket/handlers/message.ts"
      to: "src/db/schema/message.ts"
      via: "uses unique sequence constraint"
      pattern: "sequence"
---

<objective>
Fix message sequence race condition by using atomic operations and database constraints.

Purpose: Currently, messages use SELECT MAX(sequence) then INSERT with sequence+1. Under concurrent load, two messages can get the same sequence number. This causes duplicate sequences and inconsistent message ordering.

Output: Atomic sequence assignment using database-level operations and unique constraints.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/server/socket/handlers/message.ts (line 56-66 is the race condition)
@src/server/socket/handlers/thread.ts (line 55-65 is the same pattern)
@src/db/schema/message.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add unique index constraints to message schema</name>
  <files>src/db/schema/message.ts</files>
  <action>
Add unique indexes on (channelId, sequence) and (conversationId, sequence) to prevent duplicate sequences.

Update the table definition's index array to add:

```typescript
], (table) => [
  index("messages_channel_seq_idx").on(table.channelId, table.sequence),
  index("messages_conversation_seq_idx").on(table.conversationId, table.sequence),
  index("messages_author_idx").on(table.authorId),
  index("messages_parent_idx").on(table.parentId),
  index("messages_search_idx").using("gin", table.searchContent),
  // Add unique indexes for sequence integrity
  uniqueIndex("messages_channel_seq_unique_idx").on(table.channelId, table.sequence).where(sql`${table.channelId} IS NOT NULL`),
  uniqueIndex("messages_conversation_seq_unique_idx").on(table.conversationId, table.sequence).where(sql`${table.conversationId} IS NOT NULL`),
]);
```

Import `uniqueIndex` from `drizzle-orm/pg-core`.

Note: The WHERE clause ensures the unique constraint only applies when the respective ID is not null (since a message belongs to either a channel OR a conversation, not both).
  </action>
  <verify>
TypeScript compiles: `npx tsc --noEmit`
  </verify>
  <done>
Schema has unique constraints preventing duplicate sequences per channel and per conversation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Use atomic INSERT with subquery for sequence generation</name>
  <files>src/server/socket/handlers/message.ts, src/server/socket/handlers/thread.ts</files>
  <action>
Replace the two-step SELECT MAX then INSERT pattern with atomic INSERT using subquery.

**In message.ts (line ~56-78), replace:**
```typescript
// Get next sequence number
const condition = targetType === "channel"
  ? eq(messages.channelId, targetId)
  : eq(messages.conversationId, targetId);

const [maxSeq] = await db
  .select({ maxSequence: max(messages.sequence) })
  .from(messages)
  .where(condition);

const sequence = (maxSeq?.maxSequence ?? 0) + 1;

// Insert message
const [newMessage] = await db
  .insert(messages)
  .values({
    content,
    authorId: userId,
    channelId: targetType === "channel" ? targetId : null,
    conversationId: targetType === "dm" ? targetId : null,
    sequence,
  })
  .returning();
```

**With atomic approach using raw SQL for the subquery:**
```typescript
// Insert message with atomic sequence generation
const [newMessage] = await db
  .insert(messages)
  .values({
    content,
    authorId: userId,
    channelId: targetType === "channel" ? targetId : null,
    conversationId: targetType === "dm" ? targetId : null,
    sequence: sql`(
      SELECT COALESCE(MAX(${messages.sequence}), 0) + 1
      FROM ${messages}
      WHERE ${targetType === "channel"
        ? sql`${messages.channelId} = ${targetId}`
        : sql`${messages.conversationId} = ${targetId}`}
    )`,
  })
  .returning();
```

Add retry logic for the rare case of constraint violation (in case two inserts race):
```typescript
// Wrap insert in retry loop for constraint violations
let retries = 3;
let newMessage;
while (retries > 0) {
  try {
    const [result] = await db
      .insert(messages)
      .values({
        content,
        authorId: userId,
        channelId: targetType === "channel" ? targetId : null,
        conversationId: targetType === "dm" ? targetId : null,
        sequence: sql`(
          SELECT COALESCE(MAX(${messages.sequence}), 0) + 1
          FROM ${messages}
          WHERE ${targetType === "channel"
            ? sql`${messages.channelId} = ${targetId}`
            : sql`${messages.conversationId} = ${targetId}`}
        )`,
      })
      .returning();
    newMessage = result;
    break;
  } catch (error: any) {
    if (error.code === '23505' && retries > 1) { // unique_violation
      retries--;
      continue;
    }
    throw error;
  }
}

if (!newMessage) {
  throw new Error("Failed to insert message after retries");
}
```

**Apply same pattern to thread.ts (line ~55-78)** for handleThreadReply function.
  </action>
  <verify>
TypeScript compiles: `npx tsc --noEmit`
Test concurrent message sends to same channel - no duplicate sequences.
  </verify>
  <done>
Message and thread reply inserts use atomic sequence generation with retry logic.
  </done>
</task>

<task type="auto">
  <name>Task 3: Generate and run database migration</name>
  <files>Database migration</files>
  <action>
Generate and apply the migration for the new unique indexes:

```bash
cd /Users/brett/Documents/code/ocomms
npx drizzle-kit generate
npx drizzle-kit push
```

If the migration fails due to existing duplicate sequences (unlikely in dev):
1. First deduplicate any existing duplicates with a migration script
2. Then apply the unique constraint

For production deployment, include these steps in release notes.
  </action>
  <verify>
Migration runs successfully: `npx drizzle-kit push` completes without errors.
Check database has the unique indexes:
```sql
SELECT indexname FROM pg_indexes WHERE tablename = 'messages' AND indexname LIKE '%unique%';
```
  </verify>
  <done>
Database has unique constraints on message sequences, preventing duplicates at the DB level.
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles without errors
2. Migration applies successfully
3. Load test: Send 10 messages concurrently to same channel
   - All messages should have unique, sequential sequence numbers
   - No constraint violation errors (retries handle them)
</verification>

<success_criteria>
- Messages use atomic INSERT with subquery for sequence generation
- Database has unique constraints on (channelId, sequence) and (conversationId, sequence)
- Concurrent message sends don't produce duplicate sequences
- Retry logic handles rare constraint violations gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/9-authorization-data-integrity-fixes/09-06-SUMMARY.md`
</output>
